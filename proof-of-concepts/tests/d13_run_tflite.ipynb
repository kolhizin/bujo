{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import test_config as cfg\n",
    "import numpy as np\n",
    "\n",
    "import sys, os, os.path, time, datetime\n",
    "import pickle, io, json\n",
    "\n",
    "import skimage, skimage.io, skimage.transform, skimage.filters\n",
    "import sklearn, sklearn.metrics\n",
    "\n",
    "import importlib\n",
    "sys.path.append('../src/')\n",
    "import modutils\n",
    "import word_processing as wp\n",
    "import htr_model as hm\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "import editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTransformer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def transform(self, x):\n",
    "        return x\n",
    "\n",
    "    \n",
    "class SequentialTransformer:\n",
    "    def __init__(self, *args):\n",
    "        self.stages_ = args\n",
    "        \n",
    "    def transform(self, x):\n",
    "        res = x\n",
    "        for s in self.stages_:\n",
    "            res = s.transform(res)\n",
    "        return res\n",
    "    \n",
    "class LoadImageTransformer(BaseTransformer):\n",
    "    def __init__(self, path):\n",
    "        self.path_ = path\n",
    "        \n",
    "    def transform(self, x):\n",
    "        if type(x) != str:\n",
    "            raise Exception(\"LoadImageTransformer: expects filename as argument!\")\n",
    "        return skimage.io.imread(os.path.join(self.path_, x), as_grey=True)\n",
    "    \n",
    "class ConvertFloatTransformer(BaseTransformer):\n",
    "    def __init__(self, min_value = 0.0, max_value = 1.0):\n",
    "        self.min_ = min_value\n",
    "        self.max_ = max_value\n",
    "        \n",
    "    def transform(self, x):\n",
    "        if x.dtype in (np.float, np.float64, np.float32):\n",
    "            return x\n",
    "        if x.dtype == np.uint8:\n",
    "            return (x / 255.0) * (self.max_ - self.min_) + self.min_\n",
    "        if x.dtype == np.uint16:\n",
    "            return (x / 65535.0) * (self.max_ - self.min_) + self.min_\n",
    "        raise Exception(\"ConvertFloatTransformer: unexpected argument type!\")\n",
    "    \n",
    "class RandomStretchTransformer(BaseTransformer):\n",
    "    def __init__(self, min_scale = 0.66, max_scale = 1.5, fill_value=1.0):\n",
    "        self.max_ = max_scale\n",
    "        self.min_ = min_scale\n",
    "        self.fill_ = fill_value\n",
    "        \n",
    "    def transform(self, x):\n",
    "        f = np.random.uniform(self.min_, self.max_)\n",
    "        return skimage.transform.rescale(x, (1.0, f), mode='constant', cval=self.fill_)\n",
    "    \n",
    "class TransposeTransformer(BaseTransformer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def transform(self, x):\n",
    "        return np.transpose(x)\n",
    "    \n",
    "class FitSizeTransformer(BaseTransformer):\n",
    "    def __init__(self, width, height, fill_value=1.0):\n",
    "        self.w_ = width\n",
    "        self.h_ = height\n",
    "        self.fill_ = fill_value\n",
    "        self.template_ = np.ones((self.h_, self.w_)) * self.fill_\n",
    "        \n",
    "    def transform(self, x):\n",
    "        (h, w) = x.shape\n",
    "        f = max(w / self.w_, h / self.h_)\n",
    "        res = self.template_.copy()\n",
    "        rw = max(min(self.w_, int(w / f)), 1)\n",
    "        rh = max(min(self.h_, int(h / f)), 1)\n",
    "        res[0:rh, 0:rw] = skimage.transform.resize(x, (rh, rw), mode='constant', cval=self.fill_)\n",
    "        return res\n",
    "    \n",
    "class StandardizeTransformer(BaseTransformer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, x):\n",
    "        m = np.mean(x)\n",
    "        s = np.std(x)\n",
    "        if s <= 1e-9:\n",
    "            return x - m\n",
    "        return (x - m) / s\n",
    "    \n",
    "class TruncateLabelTransform(BaseTransformer):\n",
    "    def __init__(self, max_cost):\n",
    "        self.max_cost_ = max_cost\n",
    "        \n",
    "    def transform(self, x):\n",
    "        if type(x) != str:\n",
    "            raise Exception(\"TruncateLabelTransform: input expected to be of type string!\")\n",
    "        cost = 0\n",
    "        for i in range(len(x)):\n",
    "            flg = (i > 0) and (x[i] == x[i-1])\n",
    "            cost += 1 + int(flg)\n",
    "            if cost > max_cost:\n",
    "                return x[:i]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/models/htr-static-128/model_info.json', 'r') as fp:\n",
    "    model_info = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_pipeline = SequentialTransformer(\n",
    "    FitSizeTransformer(128, 32),\n",
    "    TransposeTransformer(),\n",
    "    StandardizeTransformer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 62.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fname = 'D:/Data/bujo_sample_v2/dataset.json'\n",
    "extraction_path = os.path.join(os.path.dirname(fname),\n",
    "                               os.path.basename(fname).split('.')[0])\n",
    "with open(fname, 'r', encoding='utf-8') as f:\n",
    "    src = json.load(f)\n",
    "    \n",
    "words = wp.extract_words_from_dataset(src, (1,))\n",
    "\n",
    "transforms = [{'cutoff': 0.7, 'type': 'cutoff'},\n",
    "  {'type': 'trimx'}, {'type': 'trimy'},\n",
    "  {'type': 'resize', 'y': 32}, {'type': 'invert'}]\n",
    "\n",
    "raw_lbls = [x[0] for x in words]\n",
    "\n",
    "def load_images(path, words, transform):\n",
    "    res = []\n",
    "    for (i, (word, fname)) in enumerate(tqdm.tqdm(words)):\n",
    "        src_image = skimage.io.imread(os.path.join(path, fname), as_grey=True)\n",
    "        res_image = wp.perform_transform(src_image, transform)\n",
    "        res.append(res_image)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1579 [00:00<?, ?it/s]C:\\Anaconda3\\lib\\site-packages\\skimage\\io\\_io.py:49: UserWarning: `as_grey` has been deprecated in favor of `as_gray`\n",
      "  warn('`as_grey` has been deprecated in favor of `as_gray`')\n",
      "C:\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1579/1579 [00:11<00:00, 135.78it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_imgs = load_images('D:/Data/bujo_sample_v2/dataset/', words, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_fname = 'D:/models/htr-static-128/model.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_fname)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'in_image',\n",
       "  'index': 24,\n",
       "  'shape': array([  1, 128,  32]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'out_rnn',\n",
       "  'index': 25,\n",
       "  'shape': array([  1,  32, 102]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(tfi, input_info, output_id, img, pipeline=BaseTransformer()):\n",
    "    data = pipeline.transform(img).reshape(input_info['shape']).astype(input_info['dtype'])\n",
    "    tfi.set_tensor(input_info['index'], data)\n",
    "    tfi.invoke()\n",
    "    return tfi.get_tensor(output_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1579/1579 [00:18<00:00, 84.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = []\n",
    "for img in tqdm.tqdm(raw_imgs):\n",
    "    res.append(run_inference(interpreter, input_details[0], output_details[0]['index'], raw_imgs[0], transform_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_raw_out = np.vstack(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1579, 32, 102)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_raw_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/models/htr-static-128/tf-out.pkl', 'rb') as f:\n",
    "    tf_raw_out = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 32, 102)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_raw_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.4627424, 0.4627424, 0.4627424, ..., 0.4627424, 0.4627424,\n",
       "         0.4627424],\n",
       "        [0.4627424, 0.4627424, 0.4627424, ..., 0.4627424, 0.4627424,\n",
       "         0.4627424],\n",
       "        [0.4627424, 0.4627424, 0.4627424, ..., 0.4627424, 0.4627424,\n",
       "         0.4627424],\n",
       "        ...,\n",
       "        [0.4627424, 0.4627424, 0.4627424, ..., 0.4627424, 0.4627424,\n",
       "         0.4627424],\n",
       "        [0.4627424, 0.4627424, 0.4627424, ..., 0.4627424, 0.4627424,\n",
       "         0.4627424],\n",
       "        [0.4627424, 0.4627424, 0.4627424, ..., 0.4627424, 0.4627424,\n",
       "         0.4627424]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.reshape(input_details[0]['shape']).astype(input_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
